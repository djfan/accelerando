{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7ff5b6e78850>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. library & function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "\n",
    "def eval(model, al, train, valid, rank):\n",
    "    '''\n",
    "    al: all\n",
    "    trian: trianing\n",
    "    valid: validation\n",
    "    '''\n",
    "    validMap = valid.map(lambda x:(x[0],x[1])).groupByKey().collectAsMap()\n",
    "    trainMap = train.map(lambda x:(x[0],x[1])).groupByKey().collectAsMap() \n",
    "    alSongs = al.map(lambda x:(x[1])).collect()\n",
    "    validUserScores = []\n",
    "    for user in validMap.keys():\n",
    "        userTrainSongs = trainMap.get(user) \n",
    "        userNotTrainSongs = list(set(alSongs).difference(set(userTrainSongs)))\n",
    "        userNotTrainSongsRDD = sc.parallelize([(user,x) for x in userNotTrainSongs])\n",
    "        prediction = model.predictAll(userNotTrainSongsRDD).map(lambda x: (x[2], x[1])).sortByKey(False).map(lambda x: x[1])\n",
    "        userValidSongs = validMap.get(user)\n",
    "        userValidSongsCounts = len(userValidSongs)\n",
    "        validUserScores.append(1.0 * len(set(prediction.take(userValidSongsCounts)).intersection(set(userValidSongs))) / userValidSongsCounts)\n",
    "    validUserMeanScore =  1.0 * sum(validUserScores) / len(validUserScores)\n",
    "    print \"Evaluation Score For Rank {} is {}\".format(rank, validUserMeanScore)\n",
    "    \n",
    "    \n",
    "def matchSong(targets, df):\n",
    "    targets = map(lambda x: str(x[1]), targets)\n",
    "    for r in df:\n",
    "        if str(r[0]) in targets:\n",
    "            print \"Song: {}\\nArtist: {}\".format(r[2].encode('utf-8'),r[3].encode('utf-8'))\n",
    "\n",
    "def matchArtist(targets, df):\n",
    "    targets = map(lambda x: str(x[1]), targets)\n",
    "    for r in df:\n",
    "        if str(r[1]).encode('utf-8') in targets:\n",
    "            print \"Artist: {}\".format(r[0].encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Music Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[21843] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musicData = sc.textFile('./id_train_triplets.csv', use_unicode=False).map(lambda x: x.split(',')).map(lambda x: (int(x[3]), int(x[4]), int(x[2])))\n",
    "\n",
    "trainData, validationData, testData = musicData.randomSplit([0.4, 0.4, 0.2], 13)\n",
    "trainData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 evaluation / validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ALS.trainImplicit:\n",
    ":param ratings:\n",
    "  RDD of `Rating` or (userID, productID, rating) tuple.\n",
    ":param rank:\n",
    "  Rank of the feature matrices computed (number of features).\n",
    ":param iterations:\n",
    "  Number of iterations of ALS.\n",
    "  (default: 5)\n",
    ":param lambda_:\n",
    "  Regularization parameter.\n",
    "  (default: 0.01)\n",
    ":param blocks:\n",
    "  Number of blocks used to parallelize the computation. A value\n",
    "  of -1 will use an auto-configured number of blocks.\n",
    "  (default: -1)\n",
    ":param alpha:\n",
    "  A constant used in computing confidence.\n",
    "  (default: 0.01)\n",
    ":param nonnegative:\n",
    "  A value of True will solve least-squares with nonnegativity\n",
    "  constraints.\n",
    "  (default: False)\n",
    ":param seed:\n",
    "  Random seed for initial matrix factorization model. A value\n",
    "  of None will use system time as the seed.\n",
    "  (default: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS.trainImplicit\n",
      "Evaluation Score For Rank 1 is 0.0057980409104\n",
      "Evaluation Score For Rank 3 is 0.0057980409104\n",
      "Evaluation Score For Rank 5 is 0.0154134255258\n",
      "Evaluation Score For Rank 10 is 0.00259291270527\n",
      "Evaluation Score For Rank 15 is 0.00259291270527\n",
      "Evaluation Score For Rank 20 is 0.00216076058773\n",
      "Evaluation Score For Rank 25 is 0.00129645635264\n",
      "Evaluation Score For Rank 30 is 0.00419547680784\n",
      "Evaluation Score For Rank 35 is 0.00259291270527\n",
      "Evaluation Score For Rank 40 is 0.00129645635264\n",
      "Evaluation Score For Rank 45 is 0.00259291270527\n",
      "Evaluation Score For Rank 50 is 0.00129645635264\n"
     ]
    }
   ],
   "source": [
    "ranks=[1, 3, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "print(\"ALS.trainImplicit\")\n",
    "for r in ranks:\n",
    "    Model = ALS.trainImplicit(ratings=trainData, \n",
    "                              alpha=0.01, \n",
    "                              blocks=10, \n",
    "                              iterations=5, \n",
    "                              lambda_=0.01, \n",
    "                              nonnegative=False,\n",
    "                              rank=r, \n",
    "                              seed=826) \n",
    "    eval(Model, musicData, trainData, validationData, r)\n",
    "    \n",
    "# print(\"ALS.train\")\n",
    "# for r in ranks:\n",
    "#     Model = ALS.train(ratings=trainData,\n",
    "#                       alpha=0.01,\n",
    "#                       blocks=-1, \n",
    "#                       iterations=10, \n",
    "#                       lambda_=0.01, \n",
    "#                       nonnegative=False,\n",
    "#                       rank=r,\n",
    "#                       seed=826) \n",
    "#     eval(Model, musicData, trainData, validationData, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3. model & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS.trainImplicit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=8, product=251, rating=0.0031352164611463504),\n",
       " Rating(user=8, product=176, rating=0.0026368706776661297),\n",
       " Rating(user=8, product=230, rating=0.002458122644772543)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 8 #### Input\n",
    "bestRank_1 = 5\n",
    "\n",
    "print(\"ALS.trainImplicit\")\n",
    "bestModel_1 = ALS.trainImplicit(musicData, rank=bestRank_1, seed=826, blocks=10) \n",
    "#eval(bestModel_1, musicData, trainData, testData, rank=bestRank_1)\n",
    "top3_1 = bestModel_1.recommendProducts(user,3)\n",
    "top3_1\n",
    "# bestRank_2 = 40\n",
    "# print(\"ALS.train\")\n",
    "# bestModel_2 = ALS.train(trainData, rank=bestRank_2, seed=826) \n",
    "# eval(bestModel_2, musicData, trainData, testData, rank=bestRank_2)\n",
    "# top3_2 = bestModel_2.recommendProducts(1,3)\n",
    "# print top3_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.4 match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sid: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- trackid: string (nullable = true)\n",
      " |-- songid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      "\n",
      "Song: All My Friends\n",
      "Artist: LCD Soundsystem\n",
      "Song: Harder Better Faster Stronger\n",
      "Artist: Daft Punk\n",
      "Song: Life In Technicolor ii\n",
      "Artist: Coldplay\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "songID = sqlContext.read.format('com.databricks.spark.csv'). \\\n",
    "options(header='true'). \\\n",
    "load('./SongID_int.csv')\n",
    "songID.createOrReplaceTempView(\"songID\")\n",
    "songID.printSchema()\n",
    "\n",
    "songName = sqlContext.read.format('com.databricks.spark.csv'). \\\n",
    "options(header='true'). \\\n",
    "load('./t.csv')\n",
    "songName.createOrReplaceTempView(\"songName\")\n",
    "songName.printSchema()\n",
    "\n",
    "df = sqlContext.sql('select a.sid, a.song, b.artist, b.title from songID a left join songName b on a.song = b.songid').collect()\n",
    "matchSong(top3_1, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Artist Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 group by 'artist' \n",
    "- 'uid - aid - counts' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sid: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- uid: integer (nullable = true)\n",
      " |-- sid: string (nullable = true)\n",
      " |-- counts: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- uid: integer (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- counts: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- aid: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- uid: integer (nullable = true)\n",
      " |-- aid: integer (nullable = true)\n",
      " |-- counts: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = sqlContext.createDataFrame(df)\n",
    "df2.createOrReplaceTempView(\"songMeta\")\n",
    "df2.printSchema()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"uid\", IntegerType(), True),\n",
    "    StructField(\"sid\", StringType(), True),\n",
    "    StructField(\"counts\", IntegerType(), True)])\n",
    "df3 = sqlContext.createDataFrame(musicData, schema)\n",
    "df3.createOrReplaceTempView(\"musicData\")\n",
    "df3.printSchema()\n",
    "\n",
    "df4 = sqlContext.sql(\"select a.uid, b.title from musicData a left join songMeta b on a.sid = b.sid\")\n",
    "df4.createOrReplaceTempView(\"UserArtist\")\n",
    "\n",
    "df5 = sqlContext.sql('select uid, title, count(*) from UserArtist group by uid, title').collect()\n",
    "schema = StructType([\n",
    "    StructField(\"uid\",IntegerType(),True),\n",
    "    StructField('artist',StringType(),True),\n",
    "    StructField('counts',LongType(),True)])\n",
    "df5 = sqlContext.createDataFrame(df5, schema)\n",
    "df5.printSchema()\n",
    "df5.createOrReplaceTempView(\"Artist\")\n",
    "\n",
    "df6 = sqlContext.sql('SELECT distinct a.artist, ROW_NUMBER() OVER (ORDER BY (SELECT 1)) AS aid FROM Artist AS a')\n",
    "df6.createOrReplaceTempView(\"ArtistID\")\n",
    "df6.printSchema()\n",
    "\n",
    "df7 = sqlContext.sql(\"select a.uid, b.aid, a.counts as counts from Artist a left join ArtistID b on a.artist = b.artist\")\n",
    "df7.printSchema()\n",
    "df7_rdd = df7.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[32921] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData, validationData, testData = df7_rdd.randomSplit([0.4, 0.4, 0.3], 826)\n",
    "trainData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS.trainImplicit\n",
      "Evaluation Score For Rank 1 is 0.0369167869168\n",
      "Evaluation Score For Rank 3 is 0.0459196887768\n",
      "Evaluation Score For Rank 5 is 0.0276434412149\n",
      "Evaluation Score For Rank 10 is 0.0471239606954\n",
      "Evaluation Score For Rank 15 is 0.0292293685151\n",
      "Evaluation Score For Rank 20 is 0.0497213632928\n",
      "Evaluation Score For Rank 25 is 0.0457681736253\n",
      "Evaluation Score For Rank 30 is 0.039704131847\n",
      "Evaluation Score For Rank 35 is 0.0567989417989\n",
      "Evaluation Score For Rank 40 is 0.0329399436542\n",
      "Evaluation Score For Rank 45 is 0.023852470281\n",
      "Evaluation Score For Rank 50 is 0.0385092420807\n"
     ]
    }
   ],
   "source": [
    "ranks=[1, 3, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "print(\"ALS.trainImplicit\")\n",
    "for r in ranks:\n",
    "    Model = ALS.trainImplicit(ratings=trainData, \n",
    "                              alpha=0.01, \n",
    "                              blocks=10, \n",
    "                              iterations=5, \n",
    "                              lambda_=0.01, \n",
    "                              nonnegative=False,\n",
    "                              rank=r, \n",
    "                              seed=826) \n",
    "    eval(Model, df7_rdd, trainData, validationData, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS.trainImplicit\n",
      "Evaluation Score For Rank 5 is 0.492973856209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=8, product=242, rating=0.9955798618297991),\n",
       " Rating(user=8, product=150, rating=0.9955798618297991),\n",
       " Rating(user=8, product=232, rating=0.9955798618297991)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 8 #### Input\n",
    "bestRank_artist = 35\n",
    "\n",
    "print(\"ALS.trainImplicit\")\n",
    "bestModel_artist = ALS.trainImplicit(df7_rdd, rank=bestRank_artist, seed=826, blocks=10) \n",
    "eval(bestModel_artist, df7_rdd, trainData, testData, rank=bestRank_1)\n",
    "top3_artist = bestModel_artist.recommendProducts(user,3)\n",
    "top3_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: Taylor Swift\n",
      "Artist: B.o.B\n",
      "Artist: Green Day\n"
     ]
    }
   ],
   "source": [
    "user = 11\n",
    "top3_artist = bestModel_artist.recommendProducts(user,3)\n",
    "top3_artist\n",
    "df6_df = df6.collect()\n",
    "matchArtist(top3_artist, df6_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
